{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "double_u_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abcdjdj/cs-766-project/blob/main/double_u_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "3f4bc3dc-f880-4433-85e2-c8da228e6739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW78vWjm3eGq",
        "outputId": "549083a1-f885-4113-8b23-8c881a858a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility Functions"
      ],
      "metadata": {
        "id": "tNWTHOQ_14id"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YngUNSbzeXl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "'''\n",
        "Reads the image specified by 'path' and returns it\n",
        "param : path - path of image file\n",
        "return : image as a numpy array\n",
        "'''\n",
        "def read_img(path):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "\n",
        "'''\n",
        "Converts numpy img to tensor\n",
        "param : img - numpy arr containing image data\n",
        "return : t - torch tensor of shape [1, 3, H, W]\n",
        "'''\n",
        "def img_to_tensor(img):\n",
        "    t = torch.from_numpy(img)\n",
        "    t = t.view(-1, 3, t.shape[0], t.shape[1])\n",
        "    return t\n",
        "\n",
        "'''\n",
        "Converts tensor back to numpy img\n",
        "param : t - torch tensor of shape [1, 3, H, W]\n",
        "return : img - numpy arr containing image data\n",
        "'''\n",
        "def tensor_to_img(t):\n",
        "    t = t.view(t.shape[2], t.shape[3], 3)\n",
        "    return t.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double U-Net Architecture"
      ],
      "metadata": {
        "id": "Z58WzYZp2O2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap Up inside nn.Module"
      ],
      "metadata": {
        "id": "mZPm0tGIhYtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "from imageio import imread as imread\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SqueezeAndExcite(nn.Module):\n",
        "  def __init__(self, x, ratio = 8):\n",
        "    super(SqueezeAndExcite, self).__init__()\n",
        "\n",
        "    channel_axis = 1\n",
        "    filters = x.shape[channel_axis]\n",
        "    # Architecture\n",
        "    self.avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "    self.sequential = nn.Sequential(nn.Linear(filters, filters//ratio, bias = False), nn.ReLU(), nn.Linear(filters//ratio, filters, bias = False), nn.Sigmoid())\n",
        "\n",
        "  def forward(self, x):\n",
        "    init = x\n",
        "    channel_axis = 1\n",
        "    filters = init.shape[channel_axis]\n",
        "    x = self.avgpool2d(x)\n",
        "    x = x.view(init.shape[0] , filters)\n",
        "    x = self.sequential(x)\n",
        "    x = x.view(init.shape[0], filters, 1, 1)\n",
        "\n",
        "    return torch.mul(init, x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, x, filters):\n",
        "      super().__init__()\n",
        "\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer1_conv2d(x)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      self.squeeze_and_excite = SqueezeAndExcite(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.layer1_conv2d(x)\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      x = self.layer2_conv2d(x)\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      x = self.squeeze_and_excite.forward(x)\n",
        "      return x\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, x, filter_count):\n",
        "      super().__init__()\n",
        "\n",
        "      self.layer1_avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = se.shape[1], out_channels = filter_count, kernel_size = 1, padding='same')\n",
        "      se = self.layer1_conv2d(se)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = se.shape[1])\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      se = self.layer1_relu(se)\n",
        "      self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_upsampling(se)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(dilation=1, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = y1.shape[1])\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      y1 = self.layer2_relu(y1)\n",
        "\n",
        "      self.layer3_conv2d = nn.Conv2d(dilation=6, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      self.layer3_batchnorm2d = nn.BatchNorm2d(num_features = y2.shape[1])\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      self.layer3_relu = nn.ReLU()\n",
        "      y2 = self.layer3_relu(y2)\n",
        "\n",
        "      self.layer4_conv2d = nn.Conv2d(dilation=12, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      self.layer4_batchnorm2d = nn.BatchNorm2d(num_features = y3.shape[1])\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      self.layer4_relu = nn.ReLU()\n",
        "      y3 = self.layer4_relu(y3)\n",
        "\n",
        "      self.layer5_conv2d = nn.Conv2d(dilation=18, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      self.layer5_batchnorm2d = nn.BatchNorm2d(num_features = y4.shape[1])\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      self.layer5_relu = nn.ReLU()\n",
        "      y4 = self.layer5_relu(y4)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      self.layer6_conv2d = nn.Conv2d(dilation=1, in_channels = y.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      self.layer6_batchnorm2d = nn.BatchNorm2d(num_features = y.shape[1])\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      self.layer6_relu = nn.ReLU()\n",
        "      y = self.layer6_relu(y)\n",
        "\n",
        "    def forward(self, x, filter_count):\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      se = self.layer1_conv2d(se)\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      se = self.layer1_relu(se)\n",
        "      se = self.layer1_upsampling(se)\n",
        "      #print(se.shape)\n",
        "\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      y1 = self.layer2_relu(y1)\n",
        "      #print(y1.shape)\n",
        "\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      y2 = self.layer3_relu(y2)\n",
        "      #print(y2.shape)\n",
        "\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      y3 = self.layer4_relu(y3)\n",
        "      #print(y3.shape)\n",
        "\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      y4 = self.layer5_relu(y4)\n",
        "      #print(y4.shape)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      y = self.layer6_relu(y)\n",
        "      #print(y.shape)\n",
        "      return y\n",
        "\n",
        "\n",
        "\n",
        "class DoubleUNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DoubleUNet, self).__init__()\n",
        "    #self.blocks = nn.ModuleList()\n",
        "\n",
        "    # Encoder 1\n",
        "    #self.encoder1_vgg19 = models.vgg19()\n",
        "    #self.conv_block = ConvBlock(torch.ones(1, 3, 256, 256), filters = 8)\n",
        "    #self.squeeze = SqueezeAndExcite(torch.ones(1, 10, 256, 256))\n",
        "    # To get picked up - type(self.xxx) == nn.Module\n",
        "    #self.ASPP_model = ASPP(torch.ones(2,512,16,16), 64)\n",
        "    \n",
        "\n",
        "  def squeeze_and_excite(self, inputs, ratio = 8):\n",
        "    init = inputs  #(b, 32, 128, 128)\n",
        "    channel_axis = 1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se = nn.AvgPool2d(kernel_size = (init.shape[2], init.shape[3]))(init) # (b, 32) -> (b,4)\n",
        "    se = se.view(init.shape[0] , filters)\n",
        "    se = nn.Sequential(nn.Linear(filters, filters//ratio, bias = False), nn.ReLU(), nn.Linear(filters//ratio, filters, bias = False), nn.Sigmoid())(se) # (b,32)\n",
        "    se = se.view(init.shape[0],filters,1,1) #(b, 32, 1, 1)\n",
        "\n",
        "    return torch.mul(init,se) #(b,32,128,128)\n",
        "  \n",
        "  \"\"\"\n",
        "  Function: ASPP to get high resolution feature maps\n",
        "  Inputs: feature maps, output channels desired \n",
        "  Outputs: High Res feature maps\n",
        "  \"\"\"\n",
        "  def ASPP(self, x, filter_count):\n",
        "      se = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))(x)\n",
        "      se = nn.Conv2d(in_channels = se.shape[1], out_channels = filter_count, kernel_size = 1, padding='same')(se)\n",
        "      se = nn.BatchNorm2d(num_features = se.shape[1])(se)\n",
        "      se = nn.ReLU()(se)\n",
        "      se = nn.UpsamplingBilinear2d(size=(x.shape[2], x.shape[3]))(se)\n",
        "      #print(se.shape)\n",
        "\n",
        "      y1 = nn.Conv2d(dilation=1, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y1 = nn.BatchNorm2d(num_features = y1.shape[1])(y1)\n",
        "      y1 = nn.ReLU()(y1)\n",
        "      #print(y1.shape)\n",
        "\n",
        "      y2 = nn.Conv2d(dilation=6, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y2 = nn.BatchNorm2d(num_features = y2.shape[1])(y2)\n",
        "      y2 = nn.ReLU()(y2)\n",
        "      #print(y2.shape)\n",
        "\n",
        "      y3 = nn.Conv2d(dilation=12, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y3 = nn.BatchNorm2d(num_features = y3.shape[1])(y3)\n",
        "      y3 = nn.ReLU()(y3)\n",
        "      #print(y3.shape)\n",
        "\n",
        "      y4 = nn.Conv2d(dilation=18, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y4 = nn.BatchNorm2d(num_features = y4.shape[1])(y4)\n",
        "      y4 = nn.ReLU()(y4)\n",
        "      #print(y4.shape)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      y = nn.Conv2d(dilation=1, in_channels = y.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(y)\n",
        "      y = nn.BatchNorm2d(num_features = y.shape[1])(y)\n",
        "      y = nn.ReLU()(y)\n",
        "      #print(y.shape)\n",
        "      return y\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  function: This is Encoder 1\n",
        "  params: Medical Image Input\n",
        "  return: Output of Encoder1, 4 Skip Conns for Decoder 1\n",
        "  \"\"\"\n",
        "  def encoder1(self, inputs):\n",
        "      model = self.encoder1_vgg19\n",
        "      #print(summary(model,(3,256,256)))\n",
        "\n",
        "      #skip connections from pre-trained VGG-19\n",
        "      names = [\"ReLU-4\", \"ReLU-9\", \"ReLU-18\", \"ReLU-27\", \"ReLU-36\"]\n",
        "\n",
        "      indices = [3, 8, 17, 26, 35]\n",
        "\n",
        "      skip_connections = []\n",
        "\n",
        "      def encoder1_receive_outputs(layer, _, output):\n",
        "          skip_connections.append(output)\n",
        "\n",
        "      for name, layer in model.named_children():\n",
        "          for idx in indices:\n",
        "              layer[idx].register_forward_hook(encoder1_receive_outputs)\n",
        "          break\n",
        "\n",
        "      model(inputs)\n",
        "\n",
        "      return skip_connections[-1], skip_connections[0:-1]\n",
        "\n",
        "  \"\"\"\n",
        "  Function: 2 Blocks of Convolution + BN + ReLU\n",
        "  Input: Input Activation Map, Desired output channels\n",
        "  Output: Convolved Activation Maps\n",
        "  \"\"\"\n",
        "  def conv_block(self, x, filters):\n",
        "      x = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')(x)\n",
        "      x = nn.BatchNorm2d(num_features = x.shape[1])(x)\n",
        "      x = nn.ReLU()(x)\n",
        "\n",
        "      x = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')(x)\n",
        "      x = nn.BatchNorm2d(num_features = x.shape[1])(x)\n",
        "      x = nn.ReLU()(x)\n",
        "\n",
        "      x = self.squeeze_and_excite(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "  \"\"\"\n",
        "  Function: Decoder 1\n",
        "  Params: ASPP Output, Skip Connections from Encoder1\n",
        "  Output: To be passed through output_block to get mask\n",
        "  \"\"\"\n",
        "  def decoder1(self, inputs, skip_connections):\n",
        "      num_filters = [256, 128, 64, 32]\n",
        "\n",
        "      skip_connections.reverse()\n",
        "\n",
        "      x = inputs\n",
        "\n",
        "      for i,f in enumerate(num_filters):\n",
        "          x = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))(x)\n",
        "          x = torch.cat([x, skip_connections[i]], dim=1)\n",
        "          x = self.conv_block(x, f)\n",
        "\n",
        "      return x\n",
        "\n",
        "  \"\"\"\n",
        "  Function: To get mask from decoder1 output\n",
        "  Input: Decoder1 output\n",
        "  Output: Mask for Network1\n",
        "  \"\"\"\n",
        "  def output_block(self, inputs):\n",
        "      x = nn.Conv2d(in_channels = inputs.shape[1], out_channels = 1, kernel_size = 1, padding = \"same\")(inputs)\n",
        "      x = nn.Sigmoid()(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "  def encoder2(self, inputs):\n",
        "      num_filters = [32, 64, 128, 256]\n",
        "      skip_connections = []\n",
        "      x = inputs\n",
        "\n",
        "      for f in num_filters:\n",
        "          x = self.conv_block(x, f)\n",
        "          skip_connections.append(x)\n",
        "          x = nn.MaxPool2d(kernel_size = (2,2))(x)\n",
        "\n",
        "      return x, skip_connections\n",
        "\n",
        "  def decoder2(self, inputs, skip_1, skip_2):\n",
        "      num_filters = [256, 128, 64, 32]\n",
        "\n",
        "      skip_2.reverse()\n",
        "\n",
        "      x = inputs\n",
        "\n",
        "      for i,f in enumerate(num_filters):\n",
        "          x = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))(x)\n",
        "          #print(f\"X -> {x.shape}\")\n",
        "          #print(f\"Skip1 -> {torch.Tensor(skip_1[i]).shape}\")\n",
        "          #print(f\"Skip2 -> {torch.Tensor(skip_2[i]).shape}\")\n",
        "          x = torch.cat([x, skip_1[i], skip_2[i]], dim=1)\n",
        "          x = self.conv_block(x, f)\n",
        "\n",
        "      return x\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    encoder1_op, encoder1_skip_conns = self.encoder1(inputs)\n",
        "    #print(f\"Encoder 1 o/p shape {encoder1_op.shape}\")\n",
        "    aspp_op = self.ASPP(encoder1_op, 64)\n",
        "    #print(f\"ASPP o/p shape {aspp_op.shape}\")\n",
        "    decoder1_op = self.decoder1(aspp_op, encoder1_skip_conns)\n",
        "    #print(f\"Decoder 1 o/p shape {decoder1_op.shape}\")\n",
        "    mask = self.output_block(decoder1_op)\n",
        "    #print(f\"Mask shape {mask.shape}\")\n",
        "    network1_op = inputs * mask\n",
        "    #print(f\"Network 1 o/p shape {network1_op.shape}\")\n",
        "    encoder2_op,encoder2_skip_conns = self.encoder2(network1_op)\n",
        "    #print(f\"Encoder2 o/p shape {encoder2_op.shape}\")\n",
        "    aspp2_op = self.ASPP(encoder2_op, 64)\n",
        "    #print(f\"ASPP2 o/p shape {aspp2_op.shape}\")\n",
        "    decoder2_op = self.decoder2(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "    #print(f\"Decoder2 o/p shape {decoder2_op.shape}\")\n",
        "    network2_op = self.output_block(decoder2_op)\n",
        "    #print(f\"Network 2 o/p shape {network2_op.shape}\")\n",
        "    final_output = torch.cat([mask, network2_op], dim = 1)\n",
        "    #print(f\"Final o/p shape {self.final_output.shape}\")\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "YfWoiD0OhZEQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "a2n_e6LEDncd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "num_epochs = 300\n",
        "batch_size = 7\n",
        "num_batches = num_epochs//batch_size"
      ],
      "metadata": {
        "id": "PruQBMgjDnPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-Processing"
      ],
      "metadata": {
        "id": "E6Q0MUPzgytG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = sorted(glob.glob(\"out/image/*\"))\n",
        "mask_list = sorted(glob.glob(\"out/mask/*\"))"
      ],
      "metadata": {
        "id": "fghNfMsSDak0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = [img_to_tensor(read_img(ele)) for ele in img_list]\n",
        "mask_list = [img_to_tensor(read_img(ele)) for ele in mask_list]\n",
        "\n",
        "img_data = list(zip(img_list,mask_list))\n",
        "\n",
        "data_len = len(img_list)"
      ],
      "metadata": {
        "id": "l4NA8sKWGvD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into 80-10-10\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(img_data, [round(0.8*data_len), round(0.1*data_len), data_len - round(0.8*data_len) - round(0.1*data_len)])"
      ],
      "metadata": {
        "id": "jxddbhITHQSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide Train Data Into List of Batches for Training Loop\n",
        "train_loader_x = []\n",
        "train_loader_y = []\n",
        "\n",
        "for idx in range(0, len(train_set), batch_size):\n",
        "  x_list, y_list = list(zip(*(list(train_set)[idx:idx + batch_size])))\n",
        "  train_loader_x.append(x_list)\n",
        "  train_loader_y.append(y_list)"
      ],
      "metadata": {
        "id": "cncyGZGEKihM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Optimizer, Loss Function"
      ],
      "metadata": {
        "id": "_-Pr3kgbg1c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "double_u_net = DoubleUNet()\n",
        "for parameter in double_u_net.parameters():\n",
        "  print(f\"Parameter = {parameter}\")\n",
        "\n",
        "optimizer = optim.NAdam(double_u_net.parameters(), lr = 0.001)\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "R4oix4kTg13Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0568c5-9623-442f-acdc-f1cd87c9ed02"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter = Parameter containing:\n",
            "tensor([[[[ 0.0403]],\n",
            "\n",
            "         [[ 0.0231]],\n",
            "\n",
            "         [[ 0.0298]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0326]],\n",
            "\n",
            "         [[-0.0279]],\n",
            "\n",
            "         [[-0.0363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0339]],\n",
            "\n",
            "         [[-0.0324]],\n",
            "\n",
            "         [[-0.0261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0087]],\n",
            "\n",
            "         [[ 0.0012]],\n",
            "\n",
            "         [[ 0.0167]]],\n",
            "\n",
            "\n",
            "        [[[-0.0346]],\n",
            "\n",
            "         [[ 0.0399]],\n",
            "\n",
            "         [[ 0.0029]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0095]],\n",
            "\n",
            "         [[ 0.0075]],\n",
            "\n",
            "         [[ 0.0285]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0042]],\n",
            "\n",
            "         [[-0.0385]],\n",
            "\n",
            "         [[ 0.0220]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0264]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[ 0.0128]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]],\n",
            "\n",
            "         [[-0.0186]],\n",
            "\n",
            "         [[-0.0008]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0073]],\n",
            "\n",
            "         [[ 0.0159]],\n",
            "\n",
            "         [[ 0.0407]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0321]],\n",
            "\n",
            "         [[ 0.0055]],\n",
            "\n",
            "         [[-0.0014]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0060]],\n",
            "\n",
            "         [[-0.0199]],\n",
            "\n",
            "         [[-0.0330]]]], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([ 1.1798e-02,  3.4812e-02,  1.6405e-02,  3.1682e-02,  2.0086e-02,\n",
            "         7.8437e-03,  4.1833e-02,  1.9683e-03,  6.6277e-03,  5.0992e-05,\n",
            "         4.1325e-02, -3.1088e-02, -2.4157e-02, -9.3432e-04,  3.7279e-03,\n",
            "         3.2204e-02,  2.5497e-02, -4.4078e-02, -2.7351e-02,  2.0724e-02,\n",
            "        -5.5248e-03, -1.2086e-02,  1.6832e-02,  2.9725e-02,  2.7306e-02,\n",
            "         1.8703e-02,  3.7424e-02,  2.6120e-03,  5.4214e-03, -3.0377e-03,\n",
            "         4.1121e-02, -3.0510e-02, -4.1715e-02,  3.1144e-02, -3.8597e-02,\n",
            "         4.3125e-04,  1.9993e-02, -2.5248e-02,  4.1129e-02,  1.5742e-02,\n",
            "        -1.7214e-02, -8.1786e-03, -9.2189e-03,  1.7382e-02, -3.6108e-02,\n",
            "         1.6966e-02,  4.2522e-02, -1.7124e-02, -1.6385e-02, -1.0179e-02,\n",
            "         3.4030e-02,  2.6987e-02, -2.0554e-03, -1.4503e-02, -3.3934e-02,\n",
            "         1.7908e-02, -1.6904e-02,  4.0602e-03, -1.5300e-03,  2.0082e-02,\n",
            "         3.7222e-02,  1.7972e-02, -1.3790e-02,  3.2041e-03],\n",
            "       requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([[[[-2.9905e-02]],\n",
            "\n",
            "         [[-3.7494e-02]],\n",
            "\n",
            "         [[-4.5005e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8726e-05]],\n",
            "\n",
            "         [[ 2.7540e-02]],\n",
            "\n",
            "         [[-2.2813e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.7903e-03]],\n",
            "\n",
            "         [[ 3.1924e-02]],\n",
            "\n",
            "         [[ 1.4807e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3304e-02]],\n",
            "\n",
            "         [[-3.8601e-02]],\n",
            "\n",
            "         [[-6.7570e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.3893e-02]],\n",
            "\n",
            "         [[ 1.2320e-02]],\n",
            "\n",
            "         [[-2.3580e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0690e-02]],\n",
            "\n",
            "         [[-4.4022e-02]],\n",
            "\n",
            "         [[ 2.4615e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.1851e-02]],\n",
            "\n",
            "         [[-3.9386e-02]],\n",
            "\n",
            "         [[ 4.3498e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8279e-02]],\n",
            "\n",
            "         [[ 3.7024e-02]],\n",
            "\n",
            "         [[ 1.7286e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6328e-02]],\n",
            "\n",
            "         [[-4.2491e-02]],\n",
            "\n",
            "         [[ 4.3909e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8988e-02]],\n",
            "\n",
            "         [[ 2.4809e-02]],\n",
            "\n",
            "         [[-2.4897e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1954e-02]],\n",
            "\n",
            "         [[-3.7863e-02]],\n",
            "\n",
            "         [[ 3.7765e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.1262e-03]],\n",
            "\n",
            "         [[ 3.5470e-02]],\n",
            "\n",
            "         [[-3.1344e-03]]]], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([[[[ 4.2414e-02]],\n",
            "\n",
            "         [[ 1.3159e-02]],\n",
            "\n",
            "         [[-4.0173e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3992e-02]],\n",
            "\n",
            "         [[ 3.4114e-02]],\n",
            "\n",
            "         [[ 2.9409e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.1659e-03]],\n",
            "\n",
            "         [[ 3.9130e-02]],\n",
            "\n",
            "         [[-4.0605e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3258e-02]],\n",
            "\n",
            "         [[ 2.1500e-02]],\n",
            "\n",
            "         [[-3.2515e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9861e-03]],\n",
            "\n",
            "         [[-2.8660e-02]],\n",
            "\n",
            "         [[-2.3850e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8088e-02]],\n",
            "\n",
            "         [[-1.8400e-02]],\n",
            "\n",
            "         [[-3.5062e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.6272e-03]],\n",
            "\n",
            "         [[ 4.6408e-04]],\n",
            "\n",
            "         [[-5.2194e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0567e-02]],\n",
            "\n",
            "         [[-1.7906e-02]],\n",
            "\n",
            "         [[ 3.9209e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.6863e-02]],\n",
            "\n",
            "         [[-3.1434e-02]],\n",
            "\n",
            "         [[ 1.6847e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0633e-02]],\n",
            "\n",
            "         [[ 1.2979e-02]],\n",
            "\n",
            "         [[-2.2947e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8017e-02]],\n",
            "\n",
            "         [[-1.7776e-02]],\n",
            "\n",
            "         [[-3.8351e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0803e-02]],\n",
            "\n",
            "         [[ 2.6728e-02]],\n",
            "\n",
            "         [[-4.0849e-02]]]], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([[[[-0.0132]],\n",
            "\n",
            "         [[ 0.0115]],\n",
            "\n",
            "         [[ 0.0329]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0085]],\n",
            "\n",
            "         [[ 0.0295]],\n",
            "\n",
            "         [[ 0.0125]]],\n",
            "\n",
            "\n",
            "        [[[-0.0324]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         [[-0.0118]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0402]],\n",
            "\n",
            "         [[-0.0431]],\n",
            "\n",
            "         [[-0.0104]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0280]],\n",
            "\n",
            "         [[-0.0206]],\n",
            "\n",
            "         [[ 0.0326]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0386]],\n",
            "\n",
            "         [[ 0.0377]],\n",
            "\n",
            "         [[ 0.0125]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0376]],\n",
            "\n",
            "         [[-0.0203]],\n",
            "\n",
            "         [[ 0.0133]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0157]],\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         [[ 0.0204]]],\n",
            "\n",
            "\n",
            "        [[[-0.0055]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         [[ 0.0262]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0362]],\n",
            "\n",
            "         [[ 0.0402]],\n",
            "\n",
            "         [[ 0.0139]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0158]],\n",
            "\n",
            "         [[-0.0056]],\n",
            "\n",
            "         [[ 0.0346]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221]],\n",
            "\n",
            "         [[ 0.0030]],\n",
            "\n",
            "         [[-0.0255]]]], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([[[[-0.0148]],\n",
            "\n",
            "         [[ 0.0414]],\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0388]],\n",
            "\n",
            "         [[ 0.0102]],\n",
            "\n",
            "         [[-0.0290]]],\n",
            "\n",
            "\n",
            "        [[[-0.0022]],\n",
            "\n",
            "         [[ 0.0294]],\n",
            "\n",
            "         [[ 0.0185]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0251]],\n",
            "\n",
            "         [[-0.0217]],\n",
            "\n",
            "         [[-0.0097]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0364]],\n",
            "\n",
            "         [[-0.0222]],\n",
            "\n",
            "         [[ 0.0110]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0404]],\n",
            "\n",
            "         [[ 0.0198]],\n",
            "\n",
            "         [[-0.0156]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0245]],\n",
            "\n",
            "         [[-0.0064]],\n",
            "\n",
            "         [[-0.0362]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0015]],\n",
            "\n",
            "         [[ 0.0126]],\n",
            "\n",
            "         [[-0.0368]]],\n",
            "\n",
            "\n",
            "        [[[-0.0092]],\n",
            "\n",
            "         [[-0.0182]],\n",
            "\n",
            "         [[ 0.0268]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0254]],\n",
            "\n",
            "         [[ 0.0055]],\n",
            "\n",
            "         [[ 0.0077]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0247]],\n",
            "\n",
            "         [[ 0.0229]],\n",
            "\n",
            "         [[ 0.0279]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0162]],\n",
            "\n",
            "         [[ 0.0310]],\n",
            "\n",
            "         [[-0.0009]]]], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([[[[ 0.0145]],\n",
            "\n",
            "         [[ 0.0393]],\n",
            "\n",
            "         [[-0.0107]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0528]],\n",
            "\n",
            "         [[-0.0249]],\n",
            "\n",
            "         [[-0.0166]]],\n",
            "\n",
            "\n",
            "        [[[-0.0389]],\n",
            "\n",
            "         [[ 0.0008]],\n",
            "\n",
            "         [[ 0.0378]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0506]],\n",
            "\n",
            "         [[-0.0088]],\n",
            "\n",
            "         [[-0.0207]]],\n",
            "\n",
            "\n",
            "        [[[-0.0261]],\n",
            "\n",
            "         [[ 0.0015]],\n",
            "\n",
            "         [[-0.0513]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0038]],\n",
            "\n",
            "         [[ 0.0308]],\n",
            "\n",
            "         [[ 0.0365]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0372]],\n",
            "\n",
            "         [[-0.0199]],\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0203]],\n",
            "\n",
            "         [[-0.0482]],\n",
            "\n",
            "         [[ 0.0554]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]],\n",
            "\n",
            "         [[ 0.0080]],\n",
            "\n",
            "         [[-0.0276]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0327]],\n",
            "\n",
            "         [[-0.0362]],\n",
            "\n",
            "         [[ 0.0252]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0045]],\n",
            "\n",
            "         [[ 0.0190]],\n",
            "\n",
            "         [[ 0.0448]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         [[ 0.0220]],\n",
            "\n",
            "         [[ 0.0150]]]], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
            "Parameter = Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "yVqd3LW5guZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(num_epochs):\n",
        "  for idx in range(num_batches):\n",
        "    input = torch.cat(train_loader_x[idx]) #Shape (batch_size, 3, 288, 384)\n",
        "    #final_output = build_model(input.float()) shape (batch_size, 2 , 288, 384)\n",
        "    final_output = double_u_net.forward(input.float())\n",
        "    print(final_output.shape)\n",
        "    break\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "M2EdLcoWI9Hn",
        "outputId": "eaad08cf-67ef-4dfe-ebee-dd7b82415c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-937f330ccc3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Shape (batch_size, 3, 288, 384)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#final_output = build_model(input.float()) shape (batch_size, 2 , 288, 384)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdouble_u_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-db45e11bb655>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mencoder1_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1_skip_conns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;31m#print(f\"Encoder 1 o/p shape {encoder1_op.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0maspp_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASPP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-db45e11bb655>\u001b[0m in \u001b[0;36mencoder1\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \"\"\"\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder1_vgg19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m       \u001b[0;31m#print(summary(model,(3,256,256)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DoubleUNet' object has no attribute 'encoder1_vgg19'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sXzv6SCwPKO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mIGhvRFJS3-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}