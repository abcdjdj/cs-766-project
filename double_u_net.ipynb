{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "double_u_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abcdjdj/cs-766-project/blob/main/double_u_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "3f4bc3dc-f880-4433-85e2-c8da228e6739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW78vWjm3eGq",
        "outputId": "549083a1-f885-4113-8b23-8c881a858a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility Functions"
      ],
      "metadata": {
        "id": "tNWTHOQ_14id"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YngUNSbzeXl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "'''\n",
        "Reads the image specified by 'path' and returns it\n",
        "param : path - path of image file\n",
        "return : image as a numpy array\n",
        "'''\n",
        "def read_img(path):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "\n",
        "'''\n",
        "Converts numpy img to tensor\n",
        "param : img - numpy arr containing image data\n",
        "return : t - torch tensor of shape [1, 3, H, W]\n",
        "'''\n",
        "def img_to_tensor(img):\n",
        "    t = torch.from_numpy(img)\n",
        "    t = t.view(-1, 3, t.shape[0], t.shape[1])\n",
        "    return t\n",
        "\n",
        "'''\n",
        "Converts tensor back to numpy img\n",
        "param : t - torch tensor of shape [1, 3, H, W]\n",
        "return : img - numpy arr containing image data\n",
        "'''\n",
        "def tensor_to_img(t):\n",
        "    t = t.view(t.shape[2], t.shape[3], 3)\n",
        "    return t.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double U-Net Architecture"
      ],
      "metadata": {
        "id": "Z58WzYZp2O2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap Up inside nn.Module"
      ],
      "metadata": {
        "id": "mZPm0tGIhYtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "from imageio import imread as imread\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SqueezeAndExcite(nn.Module):\n",
        "  def __init__(self, x, ratio = 8):\n",
        "    super(SqueezeAndExcite, self).__init__()\n",
        "\n",
        "    channel_axis = 1\n",
        "    filters = x.shape[channel_axis]\n",
        "    # Architecture\n",
        "    self.avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "    self.sequential = nn.Sequential(nn.Linear(filters, filters//ratio, bias = False), nn.ReLU(), nn.Linear(filters//ratio, filters, bias = False), nn.Sigmoid())\n",
        "\n",
        "  def forward(self, x):\n",
        "    init = x\n",
        "    channel_axis = 1\n",
        "    filters = init.shape[channel_axis]\n",
        "    x = self.avgpool2d(x)\n",
        "    x = x.view(init.shape[0] , filters)\n",
        "    x = self.sequential(x)\n",
        "    x = x.view(init.shape[0], filters, 1, 1)\n",
        "\n",
        "    return torch.mul(init, x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, x, filters):\n",
        "      super().__init__()\n",
        "\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer1_conv2d(x)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      self.squeeze_and_excite = SqueezeAndExcite(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.layer1_conv2d(x)\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      x = self.layer2_conv2d(x)\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      x = self.squeeze_and_excite.forward(x)\n",
        "      return x\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, x, filter_count):\n",
        "      super().__init__()\n",
        "\n",
        "      self.layer1_avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = se.shape[1], out_channels = filter_count, kernel_size = 1, padding='same')\n",
        "      se = self.layer1_conv2d(se)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = se.shape[1])\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      se = self.layer1_relu(se)\n",
        "      self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_upsampling(se)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(dilation=1, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = y1.shape[1])\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      y1 = self.layer2_relu(y1)\n",
        "\n",
        "      self.layer3_conv2d = nn.Conv2d(dilation=6, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      self.layer3_batchnorm2d = nn.BatchNorm2d(num_features = y2.shape[1])\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      self.layer3_relu = nn.ReLU()\n",
        "      y2 = self.layer3_relu(y2)\n",
        "\n",
        "      self.layer4_conv2d = nn.Conv2d(dilation=12, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      self.layer4_batchnorm2d = nn.BatchNorm2d(num_features = y3.shape[1])\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      self.layer4_relu = nn.ReLU()\n",
        "      y3 = self.layer4_relu(y3)\n",
        "\n",
        "      self.layer5_conv2d = nn.Conv2d(dilation=18, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      self.layer5_batchnorm2d = nn.BatchNorm2d(num_features = y4.shape[1])\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      self.layer5_relu = nn.ReLU()\n",
        "      y4 = self.layer5_relu(y4)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      self.layer6_conv2d = nn.Conv2d(dilation=1, in_channels = y.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      self.layer6_batchnorm2d = nn.BatchNorm2d(num_features = y.shape[1])\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      self.layer6_relu = nn.ReLU()\n",
        "      y = self.layer6_relu(y)\n",
        "\n",
        "    def forward(self, x, filter_count):\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      se = self.layer1_conv2d(se)\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      se = self.layer1_relu(se)\n",
        "      se = self.layer1_upsampling(se)\n",
        "      #print(se.shape)\n",
        "\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      y1 = self.layer2_relu(y1)\n",
        "      #print(y1.shape)\n",
        "\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      y2 = self.layer3_relu(y2)\n",
        "      #print(y2.shape)\n",
        "\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      y3 = self.layer4_relu(y3)\n",
        "      #print(y3.shape)\n",
        "\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      y4 = self.layer5_relu(y4)\n",
        "      #print(y4.shape)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      y = self.layer6_relu(y)\n",
        "      #print(y.shape)\n",
        "      return y\n",
        "\n",
        "class Encoder1(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.model = models.vgg19()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "      #skip connections from pre-trained VGG-19\n",
        "      names = [\"ReLU-4\", \"ReLU-9\", \"ReLU-18\", \"ReLU-27\", \"ReLU-36\"]\n",
        "\n",
        "      indices = [3, 8, 17, 26, 35]\n",
        "\n",
        "      skip_connections = []\n",
        "\n",
        "      def encoder1_receive_outputs(layer, _, output):\n",
        "          skip_connections.append(output)\n",
        "\n",
        "      for name, layer in self.model.named_children():\n",
        "          for idx in indices:\n",
        "              layer[idx].register_forward_hook(encoder1_receive_outputs)\n",
        "          break\n",
        "\n",
        "      self.model(inputs)\n",
        "\n",
        "      return skip_connections[-1], skip_connections[0:-1]\n",
        "\n",
        "class Decoder1(nn.Module):\n",
        "    def __init__(self, inputs, skip_connections):\n",
        "        super().__init__()\n",
        "        num_filters = [256, 128, 64, 32]\n",
        "        skip_connections.reverse()\n",
        "        x = inputs\n",
        "\n",
        "        self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer1_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[0]], dim=1)\n",
        "        self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "\n",
        "        self.layer2_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer2_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[1]], dim=1)\n",
        "        self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "\n",
        "        self.layer3_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer3_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[2]], dim=1)\n",
        "        self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "\n",
        "        self.layer4_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer4_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[3]], dim=1)\n",
        "        self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "\n",
        "        # Undo the reversal so that forward passes don't get screwed\n",
        "        skip_connections.reverse()\n",
        "    \n",
        "    def forward(self, inputs, skip_connections):\n",
        "        num_filters = [256, 128, 64, 32]\n",
        "        skip_connections.reverse()\n",
        "        x = inputs\n",
        "\n",
        "        x = self.layer1_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[0]], dim=1)\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "\n",
        "        x = self.layer2_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[1]], dim=1)\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "\n",
        "        x = self.layer3_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[2]], dim=1)\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "\n",
        "        x = self.layer4_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[3]], dim=1)\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class DoubleUNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DoubleUNet, self).__init__()\n",
        "    #self.blocks = nn.ModuleList()\n",
        "\n",
        "    # Encoder 1\n",
        "    #self.encoder1_vgg19 = models.vgg19()\n",
        "    #self.conv_block = ConvBlock(torch.ones(1, 3, 256, 256), filters = 8)\n",
        "    #self.squeeze = SqueezeAndExcite(torch.ones(1, 10, 256, 256))\n",
        "    # To get picked up - type(self.xxx) == nn.Module\n",
        "    #self.ASPP_model = ASPP(torch.ones(2,512,16,16), 64)\n",
        "    #self.encoder1 = Encoder1()\n",
        "    #self.decoder1 = Decoder1(torch.ones(1, 512, 16, 16), [torch.ones(1, 64, 256, 256), torch.ones(1, 128, 128, 128), torch.ones(1, 256, 64, 64), torch.ones(1, 512, 32, 32)])\n",
        "\n",
        "  def squeeze_and_excite(self, inputs, ratio = 8):\n",
        "    init = inputs  #(b, 32, 128, 128)\n",
        "    channel_axis = 1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se = nn.AvgPool2d(kernel_size = (init.shape[2], init.shape[3]))(init) # (b, 32) -> (b,4)\n",
        "    se = se.view(init.shape[0] , filters)\n",
        "    se = nn.Sequential(nn.Linear(filters, filters//ratio, bias = False), nn.ReLU(), nn.Linear(filters//ratio, filters, bias = False), nn.Sigmoid())(se) # (b,32)\n",
        "    se = se.view(init.shape[0],filters,1,1) #(b, 32, 1, 1)\n",
        "\n",
        "    return torch.mul(init,se) #(b,32,128,128)\n",
        "  \n",
        "  \"\"\"\n",
        "  Function: ASPP to get high resolution feature maps\n",
        "  Inputs: feature maps, output channels desired \n",
        "  Outputs: High Res feature maps\n",
        "  \"\"\"\n",
        "  def ASPP(self, x, filter_count):\n",
        "      se = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))(x)\n",
        "      se = nn.Conv2d(in_channels = se.shape[1], out_channels = filter_count, kernel_size = 1, padding='same')(se)\n",
        "      se = nn.BatchNorm2d(num_features = se.shape[1])(se)\n",
        "      se = nn.ReLU()(se)\n",
        "      se = nn.UpsamplingBilinear2d(size=(x.shape[2], x.shape[3]))(se)\n",
        "      #print(se.shape)\n",
        "\n",
        "      y1 = nn.Conv2d(dilation=1, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y1 = nn.BatchNorm2d(num_features = y1.shape[1])(y1)\n",
        "      y1 = nn.ReLU()(y1)\n",
        "      #print(y1.shape)\n",
        "\n",
        "      y2 = nn.Conv2d(dilation=6, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y2 = nn.BatchNorm2d(num_features = y2.shape[1])(y2)\n",
        "      y2 = nn.ReLU()(y2)\n",
        "      #print(y2.shape)\n",
        "\n",
        "      y3 = nn.Conv2d(dilation=12, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y3 = nn.BatchNorm2d(num_features = y3.shape[1])(y3)\n",
        "      y3 = nn.ReLU()(y3)\n",
        "      #print(y3.shape)\n",
        "\n",
        "      y4 = nn.Conv2d(dilation=18, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(x)\n",
        "      y4 = nn.BatchNorm2d(num_features = y4.shape[1])(y4)\n",
        "      y4 = nn.ReLU()(y4)\n",
        "      #print(y4.shape)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      y = nn.Conv2d(dilation=1, in_channels = y.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)(y)\n",
        "      y = nn.BatchNorm2d(num_features = y.shape[1])(y)\n",
        "      y = nn.ReLU()(y)\n",
        "      #print(y.shape)\n",
        "      return y\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  function: This is Encoder 1\n",
        "  params: Medical Image Input\n",
        "  return: Output of Encoder1, 4 Skip Conns for Decoder 1\n",
        "  \"\"\"\n",
        "  def encoder1(self, inputs):\n",
        "      model = self.encoder1_vgg19\n",
        "      #print(summary(model,(3,256,256)))\n",
        "\n",
        "      #skip connections from pre-trained VGG-19\n",
        "      names = [\"ReLU-4\", \"ReLU-9\", \"ReLU-18\", \"ReLU-27\", \"ReLU-36\"]\n",
        "\n",
        "      indices = [3, 8, 17, 26, 35]\n",
        "\n",
        "      skip_connections = []\n",
        "\n",
        "      def encoder1_receive_outputs(layer, _, output):\n",
        "          skip_connections.append(output)\n",
        "\n",
        "      for name, layer in model.named_children():\n",
        "          for idx in indices:\n",
        "              layer[idx].register_forward_hook(encoder1_receive_outputs)\n",
        "          break\n",
        "\n",
        "      model(inputs)\n",
        "\n",
        "      return skip_connections[-1], skip_connections[0:-1]\n",
        "\n",
        "  \"\"\"\n",
        "  Function: 2 Blocks of Convolution + BN + ReLU\n",
        "  Input: Input Activation Map, Desired output channels\n",
        "  Output: Convolved Activation Maps\n",
        "  \"\"\"\n",
        "  def conv_block(self, x, filters):\n",
        "      x = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')(x)\n",
        "      x = nn.BatchNorm2d(num_features = x.shape[1])(x)\n",
        "      x = nn.ReLU()(x)\n",
        "\n",
        "      x = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')(x)\n",
        "      x = nn.BatchNorm2d(num_features = x.shape[1])(x)\n",
        "      x = nn.ReLU()(x)\n",
        "\n",
        "      x = self.squeeze_and_excite(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "  \"\"\"\n",
        "  Function: Decoder 1\n",
        "  Params: ASPP Output, Skip Connections from Encoder1\n",
        "  Output: To be passed through output_block to get mask\n",
        "  \"\"\"\n",
        "  def decoder1(self, inputs, skip_connections):\n",
        "      num_filters = [256, 128, 64, 32]\n",
        "\n",
        "      skip_connections.reverse()\n",
        "\n",
        "      x = inputs\n",
        "\n",
        "      for i,f in enumerate(num_filters):\n",
        "          x = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))(x)\n",
        "          x = torch.cat([x, skip_connections[i]], dim=1)\n",
        "          x = self.conv_block(x, f)\n",
        "\n",
        "      return x\n",
        "\n",
        "  \"\"\"\n",
        "  Function: To get mask from decoder1 output\n",
        "  Input: Decoder1 output\n",
        "  Output: Mask for Network1\n",
        "  \"\"\"\n",
        "  def output_block(self, inputs):\n",
        "      x = nn.Conv2d(in_channels = inputs.shape[1], out_channels = 1, kernel_size = 1, padding = \"same\")(inputs)\n",
        "      x = nn.Sigmoid()(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "  def encoder2(self, inputs):\n",
        "      num_filters = [32, 64, 128, 256]\n",
        "      skip_connections = []\n",
        "      x = inputs\n",
        "\n",
        "      for f in num_filters:\n",
        "          x = self.conv_block(x, f)\n",
        "          skip_connections.append(x)\n",
        "          x = nn.MaxPool2d(kernel_size = (2,2))(x)\n",
        "\n",
        "      return x, skip_connections\n",
        "\n",
        "  def decoder2(self, inputs, skip_1, skip_2):\n",
        "      num_filters = [256, 128, 64, 32]\n",
        "\n",
        "      skip_2.reverse()\n",
        "\n",
        "      x = inputs\n",
        "\n",
        "      for i,f in enumerate(num_filters):\n",
        "          x = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))(x)\n",
        "          #print(f\"X -> {x.shape}\")\n",
        "          #print(f\"Skip1 -> {torch.Tensor(skip_1[i]).shape}\")\n",
        "          #print(f\"Skip2 -> {torch.Tensor(skip_2[i]).shape}\")\n",
        "          x = torch.cat([x, skip_1[i], skip_2[i]], dim=1)\n",
        "          x = self.conv_block(x, f)\n",
        "\n",
        "      return x\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    encoder1_op, encoder1_skip_conns = self.encoder1(inputs)\n",
        "    #print(f\"Encoder 1 o/p shape {encoder1_op.shape}\")\n",
        "    aspp_op = self.ASPP(encoder1_op, 64)\n",
        "    #print(f\"ASPP o/p shape {aspp_op.shape}\")\n",
        "    decoder1_op = self.decoder1(aspp_op, encoder1_skip_conns)\n",
        "    #print(f\"Decoder 1 o/p shape {decoder1_op.shape}\")\n",
        "    mask = self.output_block(decoder1_op)\n",
        "    #print(f\"Mask shape {mask.shape}\")\n",
        "    network1_op = inputs * mask\n",
        "    #print(f\"Network 1 o/p shape {network1_op.shape}\")\n",
        "    encoder2_op,encoder2_skip_conns = self.encoder2(network1_op)\n",
        "    #print(f\"Encoder2 o/p shape {encoder2_op.shape}\")\n",
        "    aspp2_op = self.ASPP(encoder2_op, 64)\n",
        "    #print(f\"ASPP2 o/p shape {aspp2_op.shape}\")\n",
        "    decoder2_op = self.decoder2(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "    #print(f\"Decoder2 o/p shape {decoder2_op.shape}\")\n",
        "    network2_op = self.output_block(decoder2_op)\n",
        "    #print(f\"Network 2 o/p shape {network2_op.shape}\")\n",
        "    final_output = torch.cat([mask, network2_op], dim = 1)\n",
        "    #print(f\"Final o/p shape {self.final_output.shape}\")\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "YfWoiD0OhZEQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "a2n_e6LEDncd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "num_epochs = 300\n",
        "batch_size = 7\n",
        "num_batches = num_epochs//batch_size"
      ],
      "metadata": {
        "id": "PruQBMgjDnPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-Processing"
      ],
      "metadata": {
        "id": "E6Q0MUPzgytG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = sorted(glob.glob(\"out/image/*\"))\n",
        "mask_list = sorted(glob.glob(\"out/mask/*\"))"
      ],
      "metadata": {
        "id": "fghNfMsSDak0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = [img_to_tensor(read_img(ele)) for ele in img_list]\n",
        "mask_list = [img_to_tensor(read_img(ele)) for ele in mask_list]\n",
        "\n",
        "img_data = list(zip(img_list,mask_list))\n",
        "\n",
        "data_len = len(img_list)"
      ],
      "metadata": {
        "id": "l4NA8sKWGvD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into 80-10-10\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(img_data, [round(0.8*data_len), round(0.1*data_len), data_len - round(0.8*data_len) - round(0.1*data_len)])"
      ],
      "metadata": {
        "id": "jxddbhITHQSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide Train Data Into List of Batches for Training Loop\n",
        "train_loader_x = []\n",
        "train_loader_y = []\n",
        "\n",
        "for idx in range(0, len(train_set), batch_size):\n",
        "  x_list, y_list = list(zip(*(list(train_set)[idx:idx + batch_size])))\n",
        "  train_loader_x.append(x_list)\n",
        "  train_loader_y.append(y_list)"
      ],
      "metadata": {
        "id": "cncyGZGEKihM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Optimizer, Loss Function"
      ],
      "metadata": {
        "id": "_-Pr3kgbg1c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "double_u_net = DoubleUNet()\n",
        "for parameter in double_u_net.parameters():\n",
        "  print(f\"Parameter = {parameter}\")\n",
        "\n",
        "optimizer = optim.NAdam(double_u_net.parameters(), lr = 0.001)\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "R4oix4kTg13Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "d2563450-2755-45b4-be01-8871b2e15281"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-56c1ed012bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Parameter = {parameter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble_u_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/nadam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, momentum_decay)\u001b[0m\n\u001b[1;32m     67\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     68\u001b[0m                         weight_decay=weight_decay, momentum_decay=momentum_decay)\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "yVqd3LW5guZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(num_epochs):\n",
        "  for idx in range(num_batches):\n",
        "    input = torch.cat(train_loader_x[idx]) #Shape (batch_size, 3, 288, 384)\n",
        "    #final_output = build_model(input.float()) shape (batch_size, 2 , 288, 384)\n",
        "    final_output = double_u_net.forward(input.float())\n",
        "    print(final_output.shape)\n",
        "    break\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "M2EdLcoWI9Hn",
        "outputId": "eaad08cf-67ef-4dfe-ebee-dd7b82415c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-937f330ccc3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Shape (batch_size, 3, 288, 384)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#final_output = build_model(input.float()) shape (batch_size, 2 , 288, 384)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdouble_u_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-db45e11bb655>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mencoder1_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1_skip_conns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;31m#print(f\"Encoder 1 o/p shape {encoder1_op.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0maspp_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASPP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-db45e11bb655>\u001b[0m in \u001b[0;36mencoder1\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \"\"\"\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder1_vgg19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m       \u001b[0;31m#print(summary(model,(3,256,256)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DoubleUNet' object has no attribute 'encoder1_vgg19'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sXzv6SCwPKO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mIGhvRFJS3-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}