{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "double_u_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abcdjdj/cs-766-project/blob/main/double_u_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "147f352f-a521-4e71-d29f-b26e5f02d024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW78vWjm3eGq",
        "outputId": "eee057d2-bede-48e1-8a52-c588d99db9e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility Functions"
      ],
      "metadata": {
        "id": "tNWTHOQ_14id"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5YngUNSbzeXl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "'''\n",
        "Reads the image specified by 'path' and returns it\n",
        "param : path - path of image file\n",
        "return : image as a numpy array\n",
        "'''\n",
        "def read_img(path):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "\n",
        "'''\n",
        "Converts numpy img to tensor\n",
        "param : img - numpy arr containing image data\n",
        "return : t - torch tensor of shape [1, 3, H, W]\n",
        "'''\n",
        "def img_to_tensor(img):\n",
        "    t = torch.from_numpy(img)\n",
        "    t = t.view(-1, 3, t.shape[0], t.shape[1])\n",
        "    return t\n",
        "\n",
        "'''\n",
        "Converts tensor back to numpy img\n",
        "param : t - torch tensor of shape [1, 3, H, W]\n",
        "return : img - numpy arr containing image data\n",
        "'''\n",
        "def tensor_to_img(t):\n",
        "    t = t.view(t.shape[2], t.shape[3], 3)\n",
        "    return t.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double U-Net Architecture"
      ],
      "metadata": {
        "id": "Z58WzYZp2O2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap Up inside nn.Module"
      ],
      "metadata": {
        "id": "mZPm0tGIhYtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "from imageio import imread as imread\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SqueezeAndExcite(nn.Module):\n",
        "  def __init__(self, x, ratio = 8):\n",
        "    super(SqueezeAndExcite, self).__init__()\n",
        "\n",
        "    channel_axis = 1\n",
        "    filters = x.shape[channel_axis]\n",
        "    # Architecture\n",
        "    self.avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "    self.sequential = nn.Sequential(nn.Linear(filters, filters//ratio, bias = False), nn.ReLU(), nn.Linear(filters//ratio, filters, bias = False), nn.Sigmoid())\n",
        "\n",
        "  def forward(self, x):\n",
        "    init = x\n",
        "    channel_axis = 1\n",
        "    filters = init.shape[channel_axis]\n",
        "    x = self.avgpool2d(x)\n",
        "    x = x.view(init.shape[0] , filters)\n",
        "    x = self.sequential(x)\n",
        "    x = x.view(init.shape[0], filters, 1, 1)\n",
        "\n",
        "    return torch.mul(init, x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, x, filters):\n",
        "      super(ConvBlock, self).__init__()\n",
        "\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer1_conv2d(x)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      self.squeeze_and_excite = SqueezeAndExcite(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.layer1_conv2d(x)\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      x = self.layer2_conv2d(x)\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      x = self.squeeze_and_excite.forward(x)\n",
        "      return x\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, x, filter_count):\n",
        "      super(ASPP, self).__init__()\n",
        "\n",
        "      self.layer1_avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = se.shape[1], out_channels = filter_count, kernel_size = 1, padding='same')\n",
        "      se = self.layer1_conv2d(se)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = se.shape[1])\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      se = self.layer1_relu(se)\n",
        "      self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_upsampling(se)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(dilation=1, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = y1.shape[1])\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      y1 = self.layer2_relu(y1)\n",
        "\n",
        "      self.layer3_conv2d = nn.Conv2d(dilation=6, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      self.layer3_batchnorm2d = nn.BatchNorm2d(num_features = y2.shape[1])\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      self.layer3_relu = nn.ReLU()\n",
        "      y2 = self.layer3_relu(y2)\n",
        "\n",
        "      self.layer4_conv2d = nn.Conv2d(dilation=12, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      self.layer4_batchnorm2d = nn.BatchNorm2d(num_features = y3.shape[1])\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      self.layer4_relu = nn.ReLU()\n",
        "      y3 = self.layer4_relu(y3)\n",
        "\n",
        "      self.layer5_conv2d = nn.Conv2d(dilation=18, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      self.layer5_batchnorm2d = nn.BatchNorm2d(num_features = y4.shape[1])\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      self.layer5_relu = nn.ReLU()\n",
        "      y4 = self.layer5_relu(y4)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      self.layer6_conv2d = nn.Conv2d(dilation=1, in_channels = y.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      self.layer6_batchnorm2d = nn.BatchNorm2d(num_features = y.shape[1])\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      self.layer6_relu = nn.ReLU()\n",
        "      y = self.layer6_relu(y)\n",
        "\n",
        "    def forward(self, x, filter_count):\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      se = self.layer1_conv2d(se)\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      se = self.layer1_relu(se)\n",
        "      se = self.layer1_upsampling(se)\n",
        "      #print(se.shape)\n",
        "\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      y1 = self.layer2_relu(y1)\n",
        "      #print(y1.shape)\n",
        "\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      y2 = self.layer3_relu(y2)\n",
        "      #print(y2.shape)\n",
        "\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      y3 = self.layer4_relu(y3)\n",
        "      #print(y3.shape)\n",
        "\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      y4 = self.layer5_relu(y4)\n",
        "      #print(y4.shape)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      y = self.layer6_relu(y)\n",
        "      #print(y.shape)\n",
        "      return y\n",
        "\n",
        "class Encoder1(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Encoder1, self).__init__()\n",
        "      self.model = models.vgg19()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "      #skip connections from pre-trained VGG-19\n",
        "      names = [\"ReLU-4\", \"ReLU-9\", \"ReLU-18\", \"ReLU-27\", \"ReLU-36\"]\n",
        "\n",
        "      indices = [3, 8, 17, 26, 35]\n",
        "\n",
        "      skip_connections = []\n",
        "\n",
        "      def encoder1_receive_outputs(layer, _, output):\n",
        "          skip_connections.append(output)\n",
        "\n",
        "      for name, layer in self.model.named_children():\n",
        "          for idx in indices:\n",
        "              layer[idx].register_forward_hook(encoder1_receive_outputs)\n",
        "          break\n",
        "\n",
        "      self.model(inputs)\n",
        "\n",
        "      return skip_connections[-1], skip_connections[0:-1]\n",
        "\n",
        "class Decoder1(nn.Module):\n",
        "    def __init__(self, inputs, skip_connections):\n",
        "        super(Decoder1, self).__init__()\n",
        "        num_filters = [256, 128, 64, 32]\n",
        "        skip_connections.reverse()\n",
        "        x = inputs\n",
        "\n",
        "        self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer1_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[0]], dim=1)\n",
        "        self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "\n",
        "        self.layer2_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer2_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[1]], dim=1)\n",
        "        self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "\n",
        "        self.layer3_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer3_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[2]], dim=1)\n",
        "        self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "\n",
        "        self.layer4_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer4_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[3]], dim=1)\n",
        "        self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "\n",
        "        # Undo the reversal so that forward passes don't get screwed\n",
        "        skip_connections.reverse()\n",
        "    \n",
        "    def forward(self, inputs, skip_connections):\n",
        "        num_filters = [256, 128, 64, 32]\n",
        "        skip_connections.reverse()\n",
        "        x = inputs\n",
        "\n",
        "        x = self.layer1_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[0]], dim=1)\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "\n",
        "        x = self.layer2_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[1]], dim=1)\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "\n",
        "        x = self.layer3_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[2]], dim=1)\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "\n",
        "        x = self.layer4_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[3]], dim=1)\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Encoder2(nn.Module):\n",
        "    def __init__(self, inputs):\n",
        "        super(Encoder2, self).__init__()\n",
        "        num_filters = [32, 64, 128, 256]\n",
        "        x = inputs\n",
        "\n",
        "        self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "        self.layer1_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer1_maxpool2d(x)\n",
        "\n",
        "        self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "        self.layer2_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer2_maxpool2d(x)\n",
        "\n",
        "        self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "        self.layer3_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer3_maxpool2d(x)\n",
        "\n",
        "        self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "        self.layer4_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer4_maxpool2d(x)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        num_filters = [32, 64, 128, 256]\n",
        "        skip_connections = []\n",
        "        x = inputs\n",
        "\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer1_maxpool2d(x)\n",
        "\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer2_maxpool2d(x)\n",
        "\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer3_maxpool2d(x)\n",
        "\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer4_maxpool2d(x)\n",
        "\n",
        "        return x, skip_connections\n",
        "\n",
        "class Decoder2(nn.Module):\n",
        "      def __init__(self, inputs, skip_1, skip_2):\n",
        "          super(Decoder2, self).__init__()\n",
        "          num_filters = [256, 128, 64, 32]\n",
        "\n",
        "          skip_2.reverse()\n",
        "          x = inputs\n",
        "\n",
        "          self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer1_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[0], skip_2[0]], dim=1)\n",
        "          self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "          x = self.layer1_convblock.forward(x)\n",
        "\n",
        "          self.layer2_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer2_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[1], skip_2[1]], dim=1)\n",
        "          self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "          x = self.layer2_convblock.forward(x)\n",
        "\n",
        "          self.layer3_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer3_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[2], skip_2[2]], dim=1)\n",
        "          self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "          x = self.layer3_convblock.forward(x)\n",
        "\n",
        "          self.layer4_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer4_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[3], skip_2[3]], dim=1)\n",
        "          self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "          x = self.layer4_convblock.forward(x)\n",
        "\n",
        "          skip_2.reverse() # Undo the reverse so we don't screw up forward()\n",
        "      \n",
        "      def forward(self, inputs, skip_1, skip_2):\n",
        "          num_filters = [256, 128, 64, 32]\n",
        "\n",
        "          skip_2.reverse()\n",
        "          x = inputs\n",
        "\n",
        "          x = self.layer1_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[0], skip_2[0]], dim=1)\n",
        "          x = self.layer1_convblock.forward(x)\n",
        "\n",
        "          x = self.layer2_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[1], skip_2[1]], dim=1)\n",
        "          x = self.layer2_convblock.forward(x)\n",
        "\n",
        "          x = self.layer3_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[2], skip_2[2]], dim=1)\n",
        "          x = self.layer3_convblock.forward(x)\n",
        "\n",
        "          x = self.layer4_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[3], skip_2[3]], dim=1)\n",
        "          x = self.layer4_convblock.forward(x)\n",
        "\n",
        "          return x\n",
        "\n",
        "class OutputBlock(nn.Module):\n",
        "      def __init__(self, inputs):\n",
        "          super(OutputBlock, self).__init__()\n",
        "          self.conv2d = nn.Conv2d(in_channels = inputs.shape[1], out_channels = 1, kernel_size = 1, padding = \"same\")\n",
        "          self.sigmoid = nn.Sigmoid()\n",
        "      \n",
        "      def forward(self, inputs):\n",
        "          x = self.conv2d(inputs)\n",
        "          x = self.sigmoid(x)\n",
        "          return x\n",
        "\n",
        "class DoubleUNet(nn.Module):\n",
        "  def __init__(self, inputs):\n",
        "      super(DoubleUNet, self).__init__()\n",
        "\n",
        "      # Encoder 1\n",
        "      self.encoder1 = Encoder1()\n",
        "      encoder1_op, encoder1_skip_conns = self.encoder1.forward(inputs)\n",
        "\n",
        "      # ASPP\n",
        "      self.aspp1 = ASPP(encoder1_op, 64)\n",
        "      aspp_op = self.aspp1.forward(encoder1_op, 64)\n",
        "\n",
        "      # Decoder 1\n",
        "      self.decoder1 = Decoder1(aspp_op, encoder1_skip_conns)\n",
        "      decoder1_op = self.decoder1.forward(aspp_op, encoder1_skip_conns)\n",
        "\n",
        "      # Output 1\n",
        "      self.outputblock1 = OutputBlock(decoder1_op)\n",
        "      mask = self.outputblock1.forward(decoder1_op)\n",
        "      network1_op = inputs * mask\n",
        "\n",
        "      # Encoder 2\n",
        "      self.encoder2 = Encoder2(network1_op)\n",
        "      encoder2_op,encoder2_skip_conns = self.encoder2.forward(network1_op)\n",
        "\n",
        "      # ASPP 2\n",
        "      self.aspp2 = ASPP(encoder2_op, 64)\n",
        "      aspp2_op = self.aspp2.forward(encoder2_op, 64)\n",
        "\n",
        "      # Decoder 2\n",
        "      self.decoder2 = Decoder2(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "      decoder2_op = self.decoder2.forward(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "\n",
        "      # Output 2\n",
        "      self.outputblock2 = OutputBlock(decoder2_op)\n",
        "      network2_op = self.outputblock2.forward(decoder2_op)\n",
        "\n",
        "      final_output = torch.cat([mask, network2_op], dim = 1)\n",
        "\n",
        "      #self.encoder1_vgg19 = models.vgg19()\n",
        "      #self.conv_block = ConvBlock(torch.ones(1, 3, 256, 256), filters = 8)\n",
        "      #self.squeeze = SqueezeAndExcite(torch.ones(1, 10, 256, 256))\n",
        "      # To get picked up - type(self.xxx) == nn.Module\n",
        "      #self.ASPP_model = ASPP(torch.ones(2,512,16,16), 64)\n",
        "      #self.encoder1 = Encoder1()\n",
        "      #self.decoder1 = Decoder1(torch.ones(1, 512, 16, 16), [torch.ones(1, 64, 256, 256), torch.ones(1, 128, 128, 128), torch.ones(1, 256, 64, 64), torch.ones(1, 512, 32, 32)])\n",
        "      #self.encoder2 = Encoder2(torch.ones(1, 3, 256, 256)) - NOT TESTED\n",
        "      #self.decoder2 = Decoder2(..) - NOT TESTED\n",
        "      #self.output = OutputBlock(torch.ones(1, 256, 64, 64))\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "      # Encoder 1\n",
        "      encoder1_op, encoder1_skip_conns = self.encoder1.forward(inputs)\n",
        "\n",
        "      # ASPP\n",
        "      aspp_op = self.aspp1.forward(encoder1_op, 64)\n",
        "\n",
        "      # Decoder 1\n",
        "      decoder1_op = self.decoder1.forward(aspp_op, encoder1_skip_conns)\n",
        "\n",
        "      # Output 1\n",
        "      mask = self.outputblock1.forward(decoder1_op)\n",
        "      network1_op = inputs * mask\n",
        "\n",
        "      # Encoder 2\n",
        "      encoder2_op,encoder2_skip_conns = self.encoder2.forward(network1_op)\n",
        "\n",
        "      # ASPP 2\n",
        "      aspp2_op = self.aspp2.forward(encoder2_op, 64)\n",
        "\n",
        "      # Decoder 2\n",
        "      decoder2_op = self.decoder2.forward(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "\n",
        "      # Output 2\n",
        "      network2_op = self.outputblock2.forward(decoder2_op)\n",
        "\n",
        "      final_output = torch.cat([mask, network2_op], dim = 1)\n",
        "      return final_output"
      ],
      "metadata": {
        "id": "YfWoiD0OhZEQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "a2n_e6LEDncd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "num_epochs = 300\n",
        "batch_size = 7\n",
        "num_batches = num_epochs//batch_size"
      ],
      "metadata": {
        "id": "PruQBMgjDnPu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-Processing"
      ],
      "metadata": {
        "id": "E6Q0MUPzgytG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = sorted(glob.glob(\"out/image/*\"))\n",
        "mask_list = sorted(glob.glob(\"out/mask/*\"))"
      ],
      "metadata": {
        "id": "fghNfMsSDak0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = [img_to_tensor(read_img(ele)) for ele in img_list]\n",
        "mask_list = [img_to_tensor(read_img(ele)) for ele in mask_list]\n",
        "\n",
        "img_data = list(zip(img_list,mask_list))\n",
        "\n",
        "data_len = len(img_list)"
      ],
      "metadata": {
        "id": "l4NA8sKWGvD4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into 80-10-10\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(img_data, [round(0.8*data_len), round(0.1*data_len), data_len - round(0.8*data_len) - round(0.1*data_len)])"
      ],
      "metadata": {
        "id": "jxddbhITHQSb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide Train Data Into List of Batches for Training Loop\n",
        "train_loader_x = []\n",
        "train_loader_y = []\n",
        "\n",
        "for idx in range(0, len(train_set), batch_size):\n",
        "  x_list, y_list = list(zip(*(list(train_set)[idx:idx + batch_size])))\n",
        "  train_loader_x.append(x_list)\n",
        "  train_loader_y.append(y_list)"
      ],
      "metadata": {
        "id": "cncyGZGEKihM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Optimizer, Loss Function"
      ],
      "metadata": {
        "id": "_-Pr3kgbg1c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "double_u_net = DoubleUNet(torch.ones(batch_size, 3, 288, 384))\n",
        "# for parameter in double_u_net.parameters():\n",
        "#    print(f\"Parameter = {parameter}\")\n",
        "\n",
        "optimizer = optim.NAdam(double_u_net.parameters(), lr = 0.001)\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "R4oix4kTg13Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "yVqd3LW5guZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(num_epochs):\n",
        "  for idx in range(num_batches):\n",
        "    input = torch.cat(train_loader_x[idx]) #Shape (batch_size, 3, 288, 384)\n",
        "    #final_output = build_model(input.float()) shape (batch_size, 2 , 288, 384)\n",
        "    final_output = double_u_net.forward(input.float())\n",
        "    print(final_output.shape)\n",
        "    break\n",
        "  break"
      ],
      "metadata": {
        "id": "M2EdLcoWI9Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87509eed-1580-481c-f2c1-fa25ab821cc9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 2, 288, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sXzv6SCwPKO3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mIGhvRFJS3-l"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}