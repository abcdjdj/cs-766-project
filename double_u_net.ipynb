{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abcdjdj/cs-766-project/blob/main/double_u_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "482229df-7931-46c7-e33b-2a52315a96d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW78vWjm3eGq",
        "outputId": "dbf0b6f1-1319-4967-8473-14052324ad42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5X6DsLSLvNm"
      },
      "source": [
        "Defining Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lQl2D3-eLufe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNWTHOQ_14id"
      },
      "source": [
        "Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5YngUNSbzeXl"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "'''\n",
        "Reads the image specified by 'path' and returns it\n",
        "param : path - path of image file\n",
        "return : image as a numpy array\n",
        "'''\n",
        "def read_img(path):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = np.clip(image - np.median(image)+127, 0, 255)\n",
        "    image = image/255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "def read_mask(path):\n",
        "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = mask/255.0\n",
        "    mask = mask.astype(np.float32)\n",
        "    #mask = np.expand_dims(mask, axis=-1)\n",
        "    return mask\n",
        "\n",
        "'''\n",
        "Converts numpy img to tensor\n",
        "param : img - numpy arr containing image data\n",
        "return : t - torch tensor of shape [1, 3, H, W]\n",
        "'''\n",
        "def img_to_tensor(img):\n",
        "    t = torch.from_numpy(img)\n",
        "    t = t.view(-1, 3, t.shape[0], t.shape[1])\n",
        "    return t\n",
        "\n",
        "def mask_to_tensor(mask):\n",
        "    t = torch.from_numpy(mask)\n",
        "    t = t.view(-1, t.shape[0], t.shape[1])\n",
        "    return t\n",
        "\n",
        "'''\n",
        "t - tensor of shape [H, W]\n",
        "'''\n",
        "def tensor_to_mask(t):\n",
        "    t = t.view(t.shape[0], t.shape[1])\n",
        "    return t.numpy()\n",
        "\n",
        "'''\n",
        "Converts tensor back to numpy img\n",
        "param : t - torch tensor of shape [1, 3, H, W]\n",
        "return : img - numpy arr containing image data\n",
        "'''\n",
        "def tensor_to_img(t):\n",
        "    t = t.view(t.shape[2], t.shape[3], 3)\n",
        "    return t.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z58WzYZp2O2r"
      },
      "source": [
        "Double U-Net Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZPm0tGIhYtC"
      },
      "source": [
        "Wrap Up inside nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YfWoiD0OhZEQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "from imageio import imread as imread\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SqueezeAndExcite(nn.Module):\n",
        "  def __init__(self, x, ratio = 8):\n",
        "    super(SqueezeAndExcite, self).__init__()\n",
        "\n",
        "    channel_axis = 1\n",
        "    filters = x.shape[channel_axis]\n",
        "    # Architecture\n",
        "    self.avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "    self.sequential = nn.Sequential(nn.Linear(filters, filters//ratio, bias = False), nn.ReLU(), nn.Linear(filters//ratio, filters, bias = False), nn.Sigmoid())\n",
        "\n",
        "  def forward(self, x):\n",
        "    init = x\n",
        "    #channel_axis = 1\n",
        "    filters = init.shape[1]\n",
        "    x = self.avgpool2d(x)\n",
        "    x = x.view(init.shape[0] , filters)\n",
        "    x = self.sequential(x)\n",
        "    x = x.view(init.shape[0], filters, 1, 1)\n",
        "\n",
        "    return torch.mul(init, x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, x, filters):\n",
        "      super(ConvBlock, self).__init__()\n",
        "\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer1_conv2d(x)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(in_channels = x.shape[1], out_channels = filters, kernel_size = 3, padding='same')\n",
        "      x = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = x.shape[1])\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      self.squeeze_and_excite = SqueezeAndExcite(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.layer1_conv2d(x)\n",
        "      x = self.layer1_batchnorm2d(x)\n",
        "      x = self.layer1_relu(x)\n",
        "\n",
        "      x = self.layer2_conv2d(x)\n",
        "      x = self.layer2_batchnorm2d(x)\n",
        "      x = self.layer2_relu(x)\n",
        "\n",
        "      x = self.squeeze_and_excite.forward(x)\n",
        "      return x\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, x, filter_count):\n",
        "      super(ASPP, self).__init__()\n",
        "\n",
        "      self.layer1_avgpool2d = nn.AvgPool2d(kernel_size = (x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      self.layer1_conv2d = nn.Conv2d(in_channels = se.shape[1], out_channels = filter_count, kernel_size = 1, padding='same')\n",
        "      se = self.layer1_conv2d(se)\n",
        "      self.layer1_batchnorm2d = nn.BatchNorm2d(num_features = se.shape[1])\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      self.layer1_relu = nn.ReLU()\n",
        "      se = self.layer1_relu(se)\n",
        "      self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(x.shape[2], x.shape[3]))\n",
        "      se = self.layer1_upsampling(se)\n",
        "\n",
        "      self.layer2_conv2d = nn.Conv2d(dilation=1, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      self.layer2_batchnorm2d = nn.BatchNorm2d(num_features = y1.shape[1])\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      self.layer2_relu = nn.ReLU()\n",
        "      y1 = self.layer2_relu(y1)\n",
        "\n",
        "      self.layer3_conv2d = nn.Conv2d(dilation=6, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      self.layer3_batchnorm2d = nn.BatchNorm2d(num_features = y2.shape[1])\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      self.layer3_relu = nn.ReLU()\n",
        "      y2 = self.layer3_relu(y2)\n",
        "\n",
        "      self.layer4_conv2d = nn.Conv2d(dilation=12, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      self.layer4_batchnorm2d = nn.BatchNorm2d(num_features = y3.shape[1])\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      self.layer4_relu = nn.ReLU()\n",
        "      y3 = self.layer4_relu(y3)\n",
        "\n",
        "      self.layer5_conv2d = nn.Conv2d(dilation=18, in_channels = x.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      self.layer5_batchnorm2d = nn.BatchNorm2d(num_features = y4.shape[1])\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      self.layer5_relu = nn.ReLU()\n",
        "      y4 = self.layer5_relu(y4)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      self.layer6_conv2d = nn.Conv2d(dilation=1, in_channels = y.shape[1], out_channels = filter_count, kernel_size = 1, padding='same', bias=False)\n",
        "      y = self.layer6_conv2d(y)\n",
        "      self.layer6_batchnorm2d = nn.BatchNorm2d(num_features = y.shape[1])\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      self.layer6_relu = nn.ReLU()\n",
        "      y = self.layer6_relu(y)\n",
        "\n",
        "    def forward(self, x, filter_count):\n",
        "      se = self.layer1_avgpool2d(x)\n",
        "      se = self.layer1_conv2d(se)\n",
        "      se = self.layer1_batchnorm2d(se)\n",
        "      se = self.layer1_relu(se)\n",
        "      se = self.layer1_upsampling(se)\n",
        "      #print(se.shape)\n",
        "\n",
        "      y1 = self.layer2_conv2d(x)\n",
        "      y1 = self.layer2_batchnorm2d(y1)\n",
        "      y1 = self.layer2_relu(y1)\n",
        "      #print(y1.shape)\n",
        "\n",
        "      y2 = self.layer3_conv2d(x)\n",
        "      y2 = self.layer3_batchnorm2d(y2)\n",
        "      y2 = self.layer3_relu(y2)\n",
        "      #print(y2.shape)\n",
        "\n",
        "      y3 = self.layer4_conv2d(x)\n",
        "      y3 = self.layer4_batchnorm2d(y3)\n",
        "      y3 = self.layer4_relu(y3)\n",
        "      #print(y3.shape)\n",
        "\n",
        "      y4 = self.layer5_conv2d(x)\n",
        "      y4 = self.layer5_batchnorm2d(y4)\n",
        "      y4 = self.layer5_relu(y4)\n",
        "      #print(y4.shape)\n",
        "\n",
        "      y = torch.cat([se, y1, y2, y3, y4], dim=1)\n",
        "      del x, se, y1, y2, y3, y4\n",
        "      y = self.layer6_conv2d(y)\n",
        "      y = self.layer6_batchnorm2d(y)\n",
        "      y = self.layer6_relu(y)\n",
        "      #print(y.shape)\n",
        "      return y\n",
        "\n",
        "class Encoder1(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Encoder1, self).__init__()\n",
        "      # self.model = models.vgg19(pretrained = True)\n",
        "      # self.vgg19_final_op = None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "      #skip connections from pre-trained VGG-19\n",
        "      names = [\"ReLU-4\", \"ReLU-9\", \"ReLU-18\", \"ReLU-27\", \"ReLU-36\"]\n",
        "      model = models.vgg19(pretrained = True)\n",
        "      if inputs.is_cuda:\n",
        "        model = model.to(device)\n",
        "\n",
        "      indices = [3, 8, 17, 26, 35]\n",
        "\n",
        "      skip_connections = []\n",
        "\n",
        "      def encoder1_receive_outputs(layer, _, output):\n",
        "          skip_connections.append(output.detach())\n",
        "          \n",
        "\n",
        "      for name, layer in model.named_children():\n",
        "          for idx in indices:\n",
        "              layer[idx].register_forward_hook(encoder1_receive_outputs)\n",
        "          break\n",
        "\n",
        "      #self.model(inputs)\n",
        "      model(inputs)\n",
        "\n",
        "      # print(f'[Encoder1] Op size = {skip_connections[-1].shape}')\n",
        "      # print(f'[Encoder1] 0 size = {skip_connections[0].shape}')\n",
        "      # print(f'[Encoder1] 1 size = {skip_connections[1].shape}')\n",
        "      # print(f'[Encoder1] 2 size = {skip_connections[2].shape}')\n",
        "      # print(f'[Encoder1] 3 size = {skip_connections[3].shape}')\n",
        "      return skip_connections[-1], skip_connections[0:-1]\n",
        "      # op = torch.ones(3, 512, 18, 24)\n",
        "      # skip_connections = [torch.ones(3, 64, 288, 384), torch.ones(3, 128, 144, 192), torch.ones(3, 256, 72, 96), torch.ones(3, 512, 36, 48)]\n",
        "      # return op, skip_connections\n",
        "\n",
        "class Decoder1(nn.Module):\n",
        "    def __init__(self, inputs, skip_connections):\n",
        "        super(Decoder1, self).__init__()\n",
        "        num_filters = [256, 128, 64, 32]\n",
        "        skip_connections.reverse()\n",
        "        x = inputs\n",
        "\n",
        "        self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer1_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[0]], dim=1)\n",
        "        self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "\n",
        "        self.layer2_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer2_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[1]], dim=1)\n",
        "        self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "\n",
        "        self.layer3_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer3_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[2]], dim=1)\n",
        "        self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "\n",
        "        self.layer4_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "        x = self.layer4_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[3]], dim=1)\n",
        "        self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "\n",
        "        # Undo the reversal so that forward passes don't get screwed\n",
        "        skip_connections.reverse()\n",
        "    \n",
        "    def forward(self, x, skip_connections):\n",
        "        num_filters = [256, 128, 64, 32]\n",
        "        skip_connections.reverse()\n",
        "\n",
        "        x = self.layer1_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[0]], dim=1)\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "\n",
        "        x = self.layer2_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[1]], dim=1)\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "\n",
        "        x = self.layer3_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[2]], dim=1)\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "\n",
        "        x = self.layer4_upsampling(x)\n",
        "        x = torch.cat([x, skip_connections[3]], dim=1)\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "\n",
        "        del skip_connections\n",
        "\n",
        "        return x\n",
        "\n",
        "class Encoder2(nn.Module):\n",
        "    def __init__(self, inputs):\n",
        "        super(Encoder2, self).__init__()\n",
        "        num_filters = [32, 64, 128, 256]\n",
        "        x = inputs\n",
        "\n",
        "        self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "        self.layer1_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer1_maxpool2d(x)\n",
        "\n",
        "        self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "        self.layer2_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer2_maxpool2d(x)\n",
        "\n",
        "        self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "        self.layer3_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer3_maxpool2d(x)\n",
        "\n",
        "        self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "        self.layer4_maxpool2d = nn.MaxPool2d(kernel_size = (2,2))\n",
        "        x = self.layer4_maxpool2d(x)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        num_filters = [32, 64, 128, 256]\n",
        "        skip_connections = []\n",
        "\n",
        "        x = self.layer1_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer1_maxpool2d(x)\n",
        "\n",
        "        x = self.layer2_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer2_maxpool2d(x)\n",
        "\n",
        "        x = self.layer3_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer3_maxpool2d(x)\n",
        "\n",
        "        x = self.layer4_convblock.forward(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.layer4_maxpool2d(x)\n",
        "\n",
        "        return x, skip_connections\n",
        "\n",
        "class Decoder2(nn.Module):\n",
        "      def __init__(self, inputs, skip_1, skip_2):\n",
        "          super(Decoder2, self).__init__()\n",
        "          num_filters = [256, 128, 64, 32]\n",
        "\n",
        "          skip_2.reverse()\n",
        "          x = inputs\n",
        "\n",
        "          self.layer1_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer1_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[0], skip_2[0]], dim=1)\n",
        "          self.layer1_convblock = ConvBlock(x, num_filters[0])\n",
        "          x = self.layer1_convblock.forward(x)\n",
        "\n",
        "          self.layer2_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer2_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[1], skip_2[1]], dim=1)\n",
        "          self.layer2_convblock = ConvBlock(x, num_filters[1])\n",
        "          x = self.layer2_convblock.forward(x)\n",
        "\n",
        "          self.layer3_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer3_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[2], skip_2[2]], dim=1)\n",
        "          self.layer3_convblock = ConvBlock(x, num_filters[2])\n",
        "          x = self.layer3_convblock.forward(x)\n",
        "\n",
        "          self.layer4_upsampling = nn.UpsamplingBilinear2d(size=(2*x.shape[2], 2*x.shape[3]))\n",
        "          x = self.layer4_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[3], skip_2[3]], dim=1)\n",
        "          self.layer4_convblock = ConvBlock(x, num_filters[3])\n",
        "          x = self.layer4_convblock.forward(x)\n",
        "\n",
        "          skip_2.reverse() # Undo the reverse so we don't screw up forward()\n",
        "      \n",
        "      def forward(self, x, skip_1, skip_2):\n",
        "          num_filters = [256, 128, 64, 32]\n",
        "\n",
        "          skip_2.reverse()\n",
        "\n",
        "          x = self.layer1_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[0], skip_2[0]], dim=1)\n",
        "          x = self.layer1_convblock.forward(x)\n",
        "\n",
        "          x = self.layer2_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[1], skip_2[1]], dim=1)\n",
        "          x = self.layer2_convblock.forward(x)\n",
        "\n",
        "          x = self.layer3_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[2], skip_2[2]], dim=1)\n",
        "          x = self.layer3_convblock.forward(x)\n",
        "\n",
        "          x = self.layer4_upsampling(x)\n",
        "          x = torch.cat([x, skip_1[3], skip_2[3]], dim=1)\n",
        "          x = self.layer4_convblock.forward(x)\n",
        "\n",
        "          del skip_1, skip_2\n",
        "\n",
        "          return x\n",
        "\n",
        "class OutputBlock(nn.Module):\n",
        "      def __init__(self, inputs):\n",
        "          super(OutputBlock, self).__init__()\n",
        "          self.conv2d = nn.Conv2d(in_channels = inputs.shape[1], out_channels = 1, kernel_size = 1, padding = \"same\")\n",
        "          self.sigmoid = nn.Sigmoid()\n",
        "      \n",
        "      def forward(self, x):\n",
        "          x = self.conv2d(x)\n",
        "          x = self.sigmoid(x)\n",
        "          return x\n",
        "\n",
        "class DoubleUNet(nn.Module):\n",
        "  def __init__(self, inputs):\n",
        "      with torch.no_grad():\n",
        "        super(DoubleUNet, self).__init__()\n",
        "\n",
        "        # Encoder 1\n",
        "        self.encoder1 = Encoder1()\n",
        "        encoder1_op, encoder1_skip_conns = self.encoder1.forward(inputs)\n",
        "\n",
        "        # ASPP\n",
        "        self.aspp1 = ASPP(encoder1_op, 64)\n",
        "        aspp_op = self.aspp1.forward(encoder1_op, 64)\n",
        "\n",
        "        # Decoder 1\n",
        "        self.decoder1 = Decoder1(aspp_op, encoder1_skip_conns)\n",
        "        decoder1_op = self.decoder1.forward(aspp_op, encoder1_skip_conns)\n",
        "\n",
        "        # Output 1\n",
        "        self.outputblock1 = OutputBlock(decoder1_op)\n",
        "        mask = self.outputblock1.forward(decoder1_op)\n",
        "        network1_op = inputs * mask\n",
        "\n",
        "        # Encoder 2\n",
        "        self.encoder2 = Encoder2(network1_op)\n",
        "        encoder2_op,encoder2_skip_conns = self.encoder2.forward(network1_op)\n",
        "\n",
        "        # ASPP 2\n",
        "        self.aspp2 = ASPP(encoder2_op, 64)\n",
        "        aspp2_op = self.aspp2.forward(encoder2_op, 64)\n",
        "\n",
        "        # Decoder 2\n",
        "        self.decoder2 = Decoder2(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "        decoder2_op = self.decoder2.forward(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "\n",
        "        # Output 2\n",
        "        self.outputblock2 = OutputBlock(decoder2_op)\n",
        "\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "      # Encoder 1\n",
        "      encoder1_op, encoder1_skip_conns = self.encoder1.forward(inputs)\n",
        "      encoder1_op = encoder1_op.to(device)\n",
        "      encoder1_skip_conns[0] = encoder1_skip_conns[0].to(device)\n",
        "      encoder1_skip_conns[1] = encoder1_skip_conns[1].to(device)\n",
        "      encoder1_skip_conns[2] = encoder1_skip_conns[2].to(device)\n",
        "      encoder1_skip_conns[3] = encoder1_skip_conns[3].to(device)\n",
        "\n",
        "      # ASPP\n",
        "      aspp_op = self.aspp1.forward(encoder1_op, 64)\n",
        "      del encoder1_op\n",
        "\n",
        "      # Decoder 1\n",
        "      decoder1_op = self.decoder1.forward(aspp_op, encoder1_skip_conns)\n",
        "      del aspp_op\n",
        "\n",
        "      # Output 1\n",
        "      mask = self.outputblock1.forward(decoder1_op)\n",
        "      network1_op = inputs * mask\n",
        "\n",
        "      # Encoder 2\n",
        "      encoder2_op,encoder2_skip_conns = self.encoder2.forward(network1_op)\n",
        "      del network1_op\n",
        "\n",
        "      # ASPP 2\n",
        "      aspp2_op = self.aspp2.forward(encoder2_op, 64)\n",
        "      del encoder2_op\n",
        "\n",
        "      # Decoder 2\n",
        "      decoder2_op = self.decoder2.forward(aspp2_op, encoder1_skip_conns, encoder2_skip_conns)\n",
        "      del aspp2_op, encoder1_skip_conns, encoder2_skip_conns\n",
        "\n",
        "      # Output 2\n",
        "      network2_op = self.outputblock2.forward(decoder2_op)\n",
        "\n",
        "      final_output = torch.cat([mask, network2_op], dim = 1)\n",
        "      del mask, network2_op\n",
        "      return final_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Q0MUPzgytG"
      },
      "source": [
        "Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fghNfMsSDak0"
      },
      "outputs": [],
      "source": [
        "img_list = sorted(glob.glob(\"out/image/*\"))\n",
        "mask_list = sorted(glob.glob(\"out/mask/*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4NA8sKWGvD4"
      },
      "outputs": [],
      "source": [
        "#img_list = [img_to_tensor(read_img(ele)) for ele in img_list]\n",
        "#mask_list = [img_to_tensor(read_img(ele)) for ele in mask_list]\n",
        "\n",
        "img_data = list(zip(img_list,mask_list))\n",
        "\n",
        "data_len = len(img_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wwj0uLy1wKZc"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 50\n",
        "batch_size = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jxddbhITHQSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7b846f-fc29-4d34-b006-d8ce9a527387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set = 12730\n",
            "Val Set = 1591\n",
            "Test Set = 1591\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "#Splitting into 80-10-10\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(img_data, [round(0.8*data_len), round(0.1*data_len), data_len - round(0.8*data_len) - round(0.1*data_len)])\n",
        "\n",
        "num_batches = math.ceil(len(train_set)/batch_size)\n",
        "print(f'Train Set = {len(train_set)}')\n",
        "print(f'Val Set = {len(val_set)}')\n",
        "print(f'Test Set = {len(test_set)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cncyGZGEKihM"
      },
      "outputs": [],
      "source": [
        "#Divide Train Data Into List of Batches for Training Loop\n",
        "train_loader_x = []\n",
        "train_loader_y = []\n",
        "\n",
        "for idx in range(0, len(train_set), batch_size):\n",
        "  if idx + batch_size > len(train_set):\n",
        "    x_tup, y_tup = list(zip(*(list(train_set)[idx:])))\n",
        "  else:\n",
        "    x_tup, y_tup = list(zip(*(list(train_set)[idx:idx + batch_size])))\n",
        "  train_loader_x.append(x_tup)\n",
        "  train_loader_y.append(y_tup)\n",
        "\n",
        "# print(f'Len = {len(train_loader_x[-1])}')\n",
        "# print(train_loader_x[-1])\n",
        "#print(train_loader_x) #is a list of tuples, in which each tuple is batch_size length\n",
        "#print(train_loader_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Pr3kgbg1c9"
      },
      "source": [
        "Define Optimizer, Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4oix4kTg13Y",
        "outputId": "6977b24c-93c3-49aa-e55b-56b61c172bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "30.92431640625\n",
            "Wed Apr 20 15:17:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    61W / 149W |    561MiB / 11441MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "tmp = torch.ones(batch_size, 3, 288, 384)\n",
        "print(torch.cuda.memory_allocated() / (1024 * 1024))\n",
        "with torch.no_grad():\n",
        "  double_u_net = DoubleUNet(tmp).to(device)\n",
        "print(torch.cuda.memory_allocated() / (1024 * 1024))\n",
        "# for parameter in double_u_net.parameters():\n",
        "#    print(f\"Parameter = {parameter}\")\n",
        "\n",
        "optimizer = optim.NAdam(double_u_net.parameters(), lr = 0.001)\n",
        "\n",
        "criterion  = nn.BCELoss()\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE_wF2tElmCx"
      },
      "source": [
        "Store Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oT--tO7zlma1"
      },
      "outputs": [],
      "source": [
        "losses = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVqd3LW5guZK"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "M2EdLcoWI9Hn",
        "outputId": "5f816e8c-6a20-41e4-fc10-ce75dfd7b89d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]\n",
            "  0%|          | 0/849 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/849 [00:12<3:02:51, 12.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 2/849 [00:24<2:54:07, 12.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/849 [00:35<4:12:48, 17.91s/it]\n",
            "  0%|          | 0/50 [00:35<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f3d5f76dc0f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mmask_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# print('After backward pass ->')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1014.00 MiB (GPU 0; 11.17 GiB total capacity; 8.22 GiB already allocated; 354.81 MiB free; 10.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# img_data = torch.ones(batch_size, 3, 288, 384).to(device)\n",
        "# mask_data = torch.ones(batch_size, 2, 288, 384).to(device)\n",
        "\n",
        "for epochs in tqdm(range(num_epochs)):\n",
        "    running_loss = 0\n",
        "    for idx in tqdm(range(num_batches)):\n",
        "        img_data = [img_to_tensor(read_img(ele)) for ele in train_loader_x[idx]]\n",
        "        img_data = torch.cat(img_data, dim = 0).to(device)\n",
        "        mask_data = [mask_to_tensor(read_mask(ele)).repeat(2, 1, 1) for ele in train_loader_y[idx]]\n",
        "        mask_data = torch.stack(mask_data, dim = 0).to(device)\n",
        "\n",
        "        # print('Before forward pass ->')\n",
        "        # print(torch.cuda.memory_allocated() / (1024 * 1024))\n",
        "        \n",
        "        mask_pred = double_u_net.forward(img_data.float())\n",
        "\n",
        "        # print('After forward pass ->')\n",
        "        # print(torch.cuda.memory_allocated() / (1024 * 1024))\n",
        "\n",
        "        del img_data\n",
        "        loss = criterion(mask_pred, mask_data)\n",
        "        del mask_data, mask_pred\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # print('After backward pass ->')\n",
        "        # print(torch.cuda.memory_allocated() / (1024 * 1024))\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += float(loss.detach())\n",
        "        del loss\n",
        "        #losses.append(running_loss)\n",
        "        #torch.cuda.empty_cache()\n",
        "        #!nvidia-smi\n",
        "\n",
        "        print('*************')\n",
        "\n",
        "    print(f\"For epoch {epochs + 1}, BCE Loss is {running_loss}\")\n",
        "\n",
        "# Save PyTorch model to disk\n",
        "torch.save(double_u_net.state_dict(), 'model_double_unet.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhlmHLlK4O4"
      },
      "outputs": [],
      "source": [
        "# validation_data = [img_to_tensor(read_img(ele[0])) for ele in val_set]\n",
        "# #validation_data = [img_to_tensor(read_img(ele)) for ele in [r'out/image/1_12.png', r'out/image/1_4.png', r'out/image/1_6.png']]\n",
        "# validation_data = torch.cat(validation_data, dim = 0).to(device)\n",
        "# validation_data = validation_data.float()\n",
        "# print(validation_data.shape)\n",
        "\n",
        "# validation_mask = double_u_net.forward(validation_data).detach().cpu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# mask_inference = tensor_to_mask(validation_mask[2][0])\n",
        "# print(mask_inference.shape)\n",
        "# for ele in val_set:\n",
        "#     print(ele[0])\n",
        "\n",
        "# #Show the image with matplotlib\n",
        "# plt.imshow(mask_inference, cmap='Greys_r')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "XuMUR80EucFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "double_u_net.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}